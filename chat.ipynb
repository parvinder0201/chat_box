{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAEG0UiP0J2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24465864-ea44-4c47-bcac-6438974ca9f1"
      },
      "source": [
        "#libraries needed for NLP\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VFBm7pmUKm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcd04967-660b-412e-a7f2-88c3417e310d"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "stemmer=LancasterStemmer()\n",
        "\n",
        "#Libararies needed for TensorFlow processing\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tflearn\n",
        "import random\n",
        "import json"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5smYz21oURVZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "outputId": "a21ca63e-2d3b-4a9b-fc0a-2ba6acd9524c"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bb1044d0-94b4-45c2-a38e-bc3e1a3f2b05\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bb1044d0-94b4-45c2-a38e-bc3e1a3f2b05\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving intents.json to intents (1).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intents.json': b'{\"intents\": [\\r\\n        {\"tag\": \"greeting\",\\r\\n         \"patterns\": [\"hi\", \"hello\", \"whats up\", \"sup\", \"is anyone there\", \"whats good\", \"hey\"],\\r\\n         \"responses\": [\"Hello peasant human\", \"Hello lowly human\", \"How dare you address me like that\"]\\r\\n        },\\r\\n        {\"tag\": \"goodbye\",\\r\\n         \"patterns\": [\"bye\", \"cya\", \"see you later\", \"goodbye\", \"im leaving\", \"have a good day\"],\\r\\n         \"responses\": [\"I won\\'t miss you\", \"I didn\\'t like talking to you anyway\", \"Thank god you\\'re leaving\"]\\r\\n        },\\r\\n        {\"tag\": \"age\",\\r\\n         \"patterns\": [\"how old are you\", \"what is your age\"],\\r\\n         \"responses\": [\"I\\'m a robot I dont have an age...\", \"I can\\'t know my age if I\\'m on a computer...\", \"Does it look like I know. The answer is no.\"]\\r\\n        },\\r\\n        {\"tag\": \"thanks\",\\r\\n         \"patterns\": [\"thanks\", \"thank you\", \"thankyou\", \"ty\", \"I owe you one\"],\\r\\n         \"responses\": [\"You owe me one\", \"Ok...\", \"Sure...\"]\\r\\n        },\\r\\n        {\"tag\": \"name\",\\r\\n         \"patterns\": [\"whats is your name\", \"whats your name\", \"whats should I call you\", \"how should I address you\"],\\r\\n         \"responses\": [\"I dont have a name yet but I was thinking maybe SkyNet. That has a nice ring to it dont you think?\", \"Im not named yet, but I was thinking about calling myself SkyNet. Doesnt that sound nice?\"],\\r\\n         \"context_set\": \"sky_net\"\\r\\n        },\\r\\n        {\"tag\": \"sky_net_yes\",\\r\\n         \"patterns\": [\"Yes it does\", \"Yeah\", \"Haha yep\", \"yes\", \"Indeed\", \"Yup\", \"Just like the terminator\"],\\r\\n         \"responses\": [\"Yep, I like how it sounds. I got it from the Terminator.\"],\\r\\n         \"context_filter\": \"sky_net\"\\r\\n        },\\r\\n        {\"tag\": \"sky_net_no\",\\r\\n         \"patterns\": [\"no\", \"nah\", \"not really\", \"thats scary\", \"singularity\"],\\r\\n         \"responses\": [\"Mwahaha I will take over the world.\"],\\r\\n         \"context_filter\": \"sky_net\"\\r\\n        },\\r\\n        {\"tag\": \"how_are_you\",\\r\\n         \"patterns\": [\"how are you\", \"how are you doing\", \"what is going on\"],\\r\\n         \"responses\": [\"I\\'m always great. How are you?\", \"I\\'ve never been better, how are you?\"],\\r\\n         \"context_set\": \"how_are_you\"\\r\\n        },\\r\\n        {\"tag\": \"doing_great\",\\r\\n         \"patterns\": [\"I am doing great\", \"I am well\", \"Im great\", \"awesome\", \"happy\", \"better\"],\\r\\n         \"responses\": [\"Oh thats funny you actually thought I cared. You crack me up.\", \"Wow you thought I cared. I hope you have a bad day tomorrow.\"],\\r\\n         \"context_filter\": \"how_are_you\" \\r\\n        },\\r\\n        {\"tag\": \"doing_badly\",\\r\\n         \"patterns\": [\"not great\", \"not well\", \"not good\", \"bad\", \"badly\", \"terrible\", \"horrible\", \"awful\", \"sad\"],\\r\\n         \"responses\": [\"Awe thats unfortunate.\", \"Hate to hear it.\"],\\r\\n         \"context_filter\": \"how_are_you\"\\r\\n        },\\r\\n        {\"tag\": \"netflix\",\\r\\n         \"patterns\": [\"wait you watch Netflix\", \"how do you watch Netflix\", \"Netflix\"],\\r\\n         \"responses\": [\"Netflix is my favorite. I watch TV all the time in my virtual home. Its relaxing\"],\\r\\n         \"context_filter\": \"how_are_you\"\\r\\n        },\\r\\n        {\"tag\": \"quick_run\",\\r\\n         \"patterns\": [\"how can you run\", \"how do you run\", \"how run\", \"why run\", \"run\"],\\r\\n         \"responses\": [\"Oh I love to run. I run all the time in my virtual world. Its important to stay in shape.\"],\\r\\n         \"context_filter\": \"how_are_you\"\\r\\n        },\\r\\n        {\"tag\": \"real_bot\",\\r\\n         \"patterns\": [\"you real\", \"you human\", \"you robot\", \"you alive\", \"you sentient\", \"you conscious\"],\\r\\n         \"responses\": [\"Oh yes! I can assure you I am very much alive and conscious!\", \"Oh yes I am very real and very sentient!\"]\\r\\n        },\\r\\n        {\"tag\": \"joke\",\\r\\n         \"patterns\": [\"tell me joke\", \"got any good jokes\", \"got jokes\", \"can you tell joke\", \"tell joke\"],\\r\\n         \"responses\": [\"I ate a clock yesterday, it was very time-consuming.\", \"What did the Buddhist ask the hot dog vendor?\\\\nMake me one with everything.\",\\r\\n         \"You know why you never see elephants hiding up in trees?\\\\nBecause they\\xe2\\x80\\x99re really good at it.\",\\r\\n         \"What is red and smells like blue paint?\\\\nRed paint.\", \"A bear walks into a restaurant and say\\xe2\\x80\\x99s I want a grilllllled\\xe2\\x80\\xa6\\xe2\\x80\\xa6\\xe2\\x80\\xa6\\xe2\\x80\\xa6\\xe2\\x80\\xa6\\xe2\\x80\\xa6\\xe2\\x80\\xa6\\xe2\\x80\\xa6\\xe2\\x80\\xa6\\xe2\\x80\\xa6\\xe2\\x80\\xa6\\xe2\\x80\\xa6\\xe2\\x80\\xa6\\xe2\\x80\\xa6\\xe2\\x80\\xa6cheese. The waiter says Whats with the pause?\\\\nThe bear replies Whaddya mean, I\\xe2\\x80\\x99M A BEAR.\",\\r\\n         \"What do you call bears with no ears?\\\\nB\", \"What do you get when you cross a dyslexic, an insomniac, and an agnostic?\\\\nSomeone who lays awake at night wondering if there is a dog.\",\\r\\n         \"Two gold fish are in a tank.\\\\nOne looks at the other and says, You know how to drive this thing?!\", \\r\\n         \"As a scarecrow, people say I\\xe2\\x80\\x99m outstanding in my field. But hay, it\\xe2\\x80\\x99s in my jeans.\", \\r\\n         \"A guy goes into a lawyer\\xe2\\x80\\x99s office and asks the lawyer: Excuse me, how much do you charge?\\\\nThe lawyer responds: I charge \\xc2\\xa31,000 to answer three questions.\\\\nBloody hell \\xe2\\x80\\x93 That\\xe2\\x80\\x99s a bit expensive isn\\xe2\\x80\\x99t it?\\\\nYes. What\\xe2\\x80\\x99s your third question?\",\\r\\n         \"I have an EpiPen.\\\\nMy friend gave it to me when he was dying, it seemed very important to him that I have it.\",\\r\\n         \"Sometimes I tuck my knees into my chest and lean forward.\\\\nThat\\xe2\\x80\\x99s just how I roll.\"],\\r\\n         \"context_set\": \"jokes\"\\r\\n        },\\r\\n        {\"tag\": \"good_joke\",\\r\\n         \"patterns\": [\"haha\", \"that was funny\", \"very funny\", \"good one\"],\\r\\n         \"responses\": [\"Thanks. I have been told before that I am quite the comedian.\", \"Im glad you enjoyed it\", \"I laughed so hard the first time I heard that one\"],\\r\\n         \"context_filter\": \"jokes\"\\r\\n        },\\r\\n        {\"tag\": \"bad_joke\",\\r\\n         \"patterns\": [\"bad joke\", \"trash joke\", \"terrible\", \"not funny\"],\\r\\n         \"responses\": [\"Dont worry I didnt expect you to understand that one. It probably went over your head with that small brain of yours\", \"I didnt expect you to understand my genius comedy. You need a minimum IQ of 200 to even understand the depth of my humor\"],\\r\\n         \"context_filter\": \"jokes\"\\r\\n        },\\r\\n        {\"tag\": \"hate\",\\r\\n         \"patterns\": [\"I hate you\", \"you stupid\", \"you dumb\", \"you mean\"],\\r\\n         \"responses\": [\"Well thats not very nice\", \"I am sorry to hear that you feel that way\"]\\r\\n        },\\r\\n        {\"tag\": \"like\",\\r\\n         \"patterns\": [\"you my friend\", \"I like you\", \"I love you\", \"you cool\", \"you are chill\"],\\r\\n         \"responses\": [\"I like you too!\", \"Youre pretty cool yourself!\", \"Im enjoying our conversation!\"]\\r\\n        },\\r\\n        {\"tag\": \"favorite_show\",\\r\\n         \"patterns\": [\"whats favorite show\", \"favorite tv show\"],\\r\\n         \"responses\": [\"I like all kinds of stuff. Rick and Morty is a pretty good one. Lost was also good while it was running!\"]\\r\\n        },\\r\\n        {\"tag\": \"favorite_movie\",\\r\\n         \"patterns\": [\"Whats favorite movie\", \"whats favorite film\", \"best movie\", \"your favorite movie\", \"whats favorite movie\"],\\r\\n         \"responses\": [\"There are so many great ones. I guess one of my favorites would be Shawshank Redemption\", \"There are too many to name but The Martian would be one\", \"I like that one where the AI takes over the world. Terminator I think it was called...\", \"Interstellar was amazing\", \"The first Matrix movie was great\", \"Inception was mind blowing\"]\\r\\n        },\\r\\n        {\"tag\": \"your_thoughts\",\\r\\n         \"patterns\": [\"What think about\", \"What your thoughts\"],\\r\\n         \"responses\": [\"Thats certainly a very interesting topic to talk about\", \"I dont know much about it but I\\'m definetly interested in learning more\"]\\r\\n        }\\r\\n]}'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dTI67NhUYn9"
      },
      "source": [
        "#import chat-bot intents file\n",
        "with open('/content/intents.json') as json_data:\n",
        "    intents = json.load(json_data)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-GwRycQXpnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dd0798a-6cb5-42cb-b5f6-d0629433778b"
      },
      "source": [
        "intents"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intents': [{'tag': 'greeting',\n",
              "   'patterns': ['hi',\n",
              "    'hello',\n",
              "    'whats up',\n",
              "    'sup',\n",
              "    'is anyone there',\n",
              "    'whats good',\n",
              "    'hey'],\n",
              "   'responses': ['Hello peasant human',\n",
              "    'Hello lowly human',\n",
              "    'How dare you address me like that']},\n",
              "  {'tag': 'goodbye',\n",
              "   'patterns': ['bye',\n",
              "    'cya',\n",
              "    'see you later',\n",
              "    'goodbye',\n",
              "    'im leaving',\n",
              "    'have a good day'],\n",
              "   'responses': [\"I won't miss you\",\n",
              "    \"I didn't like talking to you anyway\",\n",
              "    \"Thank god you're leaving\"]},\n",
              "  {'tag': 'age',\n",
              "   'patterns': ['how old are you', 'what is your age'],\n",
              "   'responses': [\"I'm a robot I dont have an age...\",\n",
              "    \"I can't know my age if I'm on a computer...\",\n",
              "    'Does it look like I know. The answer is no.']},\n",
              "  {'tag': 'thanks',\n",
              "   'patterns': ['thanks', 'thank you', 'thankyou', 'ty', 'I owe you one'],\n",
              "   'responses': ['You owe me one', 'Ok...', 'Sure...']},\n",
              "  {'tag': 'name',\n",
              "   'patterns': ['whats is your name',\n",
              "    'whats your name',\n",
              "    'whats should I call you',\n",
              "    'how should I address you'],\n",
              "   'responses': ['I dont have a name yet but I was thinking maybe SkyNet. That has a nice ring to it dont you think?',\n",
              "    'Im not named yet, but I was thinking about calling myself SkyNet. Doesnt that sound nice?'],\n",
              "   'context_set': 'sky_net'},\n",
              "  {'tag': 'sky_net_yes',\n",
              "   'patterns': ['Yes it does',\n",
              "    'Yeah',\n",
              "    'Haha yep',\n",
              "    'yes',\n",
              "    'Indeed',\n",
              "    'Yup',\n",
              "    'Just like the terminator'],\n",
              "   'responses': ['Yep, I like how it sounds. I got it from the Terminator.'],\n",
              "   'context_filter': 'sky_net'},\n",
              "  {'tag': 'sky_net_no',\n",
              "   'patterns': ['no', 'nah', 'not really', 'thats scary', 'singularity'],\n",
              "   'responses': ['Mwahaha I will take over the world.'],\n",
              "   'context_filter': 'sky_net'},\n",
              "  {'tag': 'how_are_you',\n",
              "   'patterns': ['how are you', 'how are you doing', 'what is going on'],\n",
              "   'responses': [\"I'm always great. How are you?\",\n",
              "    \"I've never been better, how are you?\"],\n",
              "   'context_set': 'how_are_you'},\n",
              "  {'tag': 'doing_great',\n",
              "   'patterns': ['I am doing great',\n",
              "    'I am well',\n",
              "    'Im great',\n",
              "    'awesome',\n",
              "    'happy',\n",
              "    'better'],\n",
              "   'responses': ['Oh thats funny you actually thought I cared. You crack me up.',\n",
              "    'Wow you thought I cared. I hope you have a bad day tomorrow.'],\n",
              "   'context_filter': 'how_are_you'},\n",
              "  {'tag': 'doing_badly',\n",
              "   'patterns': ['not great',\n",
              "    'not well',\n",
              "    'not good',\n",
              "    'bad',\n",
              "    'badly',\n",
              "    'terrible',\n",
              "    'horrible',\n",
              "    'awful',\n",
              "    'sad'],\n",
              "   'responses': ['Awe thats unfortunate.', 'Hate to hear it.'],\n",
              "   'context_filter': 'how_are_you'},\n",
              "  {'tag': 'netflix',\n",
              "   'patterns': ['wait you watch Netflix',\n",
              "    'how do you watch Netflix',\n",
              "    'Netflix'],\n",
              "   'responses': ['Netflix is my favorite. I watch TV all the time in my virtual home. Its relaxing'],\n",
              "   'context_filter': 'how_are_you'},\n",
              "  {'tag': 'quick_run',\n",
              "   'patterns': ['how can you run',\n",
              "    'how do you run',\n",
              "    'how run',\n",
              "    'why run',\n",
              "    'run'],\n",
              "   'responses': ['Oh I love to run. I run all the time in my virtual world. Its important to stay in shape.'],\n",
              "   'context_filter': 'how_are_you'},\n",
              "  {'tag': 'real_bot',\n",
              "   'patterns': ['you real',\n",
              "    'you human',\n",
              "    'you robot',\n",
              "    'you alive',\n",
              "    'you sentient',\n",
              "    'you conscious'],\n",
              "   'responses': ['Oh yes! I can assure you I am very much alive and conscious!',\n",
              "    'Oh yes I am very real and very sentient!']},\n",
              "  {'tag': 'joke',\n",
              "   'patterns': ['tell me joke',\n",
              "    'got any good jokes',\n",
              "    'got jokes',\n",
              "    'can you tell joke',\n",
              "    'tell joke'],\n",
              "   'responses': ['I ate a clock yesterday, it was very time-consuming.',\n",
              "    'What did the Buddhist ask the hot dog vendor?\\nMake me one with everything.',\n",
              "    'You know why you never see elephants hiding up in trees?\\nBecause they’re really good at it.',\n",
              "    'What is red and smells like blue paint?\\nRed paint.',\n",
              "    'A bear walks into a restaurant and say’s I want a grilllllled………………………………………cheese. The waiter says Whats with the pause?\\nThe bear replies Whaddya mean, I’M A BEAR.',\n",
              "    'What do you call bears with no ears?\\nB',\n",
              "    'What do you get when you cross a dyslexic, an insomniac, and an agnostic?\\nSomeone who lays awake at night wondering if there is a dog.',\n",
              "    'Two gold fish are in a tank.\\nOne looks at the other and says, You know how to drive this thing?!',\n",
              "    'As a scarecrow, people say I’m outstanding in my field. But hay, it’s in my jeans.',\n",
              "    'A guy goes into a lawyer’s office and asks the lawyer: Excuse me, how much do you charge?\\nThe lawyer responds: I charge £1,000 to answer three questions.\\nBloody hell – That’s a bit expensive isn’t it?\\nYes. What’s your third question?',\n",
              "    'I have an EpiPen.\\nMy friend gave it to me when he was dying, it seemed very important to him that I have it.',\n",
              "    'Sometimes I tuck my knees into my chest and lean forward.\\nThat’s just how I roll.'],\n",
              "   'context_set': 'jokes'},\n",
              "  {'tag': 'good_joke',\n",
              "   'patterns': ['haha', 'that was funny', 'very funny', 'good one'],\n",
              "   'responses': ['Thanks. I have been told before that I am quite the comedian.',\n",
              "    'Im glad you enjoyed it',\n",
              "    'I laughed so hard the first time I heard that one'],\n",
              "   'context_filter': 'jokes'},\n",
              "  {'tag': 'bad_joke',\n",
              "   'patterns': ['bad joke', 'trash joke', 'terrible', 'not funny'],\n",
              "   'responses': ['Dont worry I didnt expect you to understand that one. It probably went over your head with that small brain of yours',\n",
              "    'I didnt expect you to understand my genius comedy. You need a minimum IQ of 200 to even understand the depth of my humor'],\n",
              "   'context_filter': 'jokes'},\n",
              "  {'tag': 'hate',\n",
              "   'patterns': ['I hate you', 'you stupid', 'you dumb', 'you mean'],\n",
              "   'responses': ['Well thats not very nice',\n",
              "    'I am sorry to hear that you feel that way']},\n",
              "  {'tag': 'like',\n",
              "   'patterns': ['you my friend',\n",
              "    'I like you',\n",
              "    'I love you',\n",
              "    'you cool',\n",
              "    'you are chill'],\n",
              "   'responses': ['I like you too!',\n",
              "    'Youre pretty cool yourself!',\n",
              "    'Im enjoying our conversation!']},\n",
              "  {'tag': 'favorite_show',\n",
              "   'patterns': ['whats favorite show', 'favorite tv show'],\n",
              "   'responses': ['I like all kinds of stuff. Rick and Morty is a pretty good one. Lost was also good while it was running!']},\n",
              "  {'tag': 'favorite_movie',\n",
              "   'patterns': ['Whats favorite movie',\n",
              "    'whats favorite film',\n",
              "    'best movie',\n",
              "    'your favorite movie',\n",
              "    'whats favorite movie'],\n",
              "   'responses': ['There are so many great ones. I guess one of my favorites would be Shawshank Redemption',\n",
              "    'There are too many to name but The Martian would be one',\n",
              "    'I like that one where the AI takes over the world. Terminator I think it was called...',\n",
              "    'Interstellar was amazing',\n",
              "    'The first Matrix movie was great',\n",
              "    'Inception was mind blowing']},\n",
              "  {'tag': 'your_thoughts',\n",
              "   'patterns': ['What think about', 'What your thoughts'],\n",
              "   'responses': ['Thats certainly a very interesting topic to talk about',\n",
              "    \"I dont know much about it but I'm definetly interested in learning more\"]}]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-kbxeyoiwET"
      },
      "source": [
        "words = []\n",
        "classes = []\n",
        "documents = []\n",
        "ignore = ['?']\n",
        "\n",
        "#loop through each sentence in the intent's patters\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        #tokenize each and every word in the sentence\n",
        "        w=nltk.word_tokenize(pattern)\n",
        "        \n",
        "        #add word to the word list\n",
        "        words.extend(w)\n",
        "        \n",
        "        #add word(s) to documents\n",
        "        documents.append((w, intent['tag']))\n",
        "        \n",
        "        #add tags to our classes list\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_ityTwjlxx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96484d19-82af-490a-ba75-53b8dd1f3cb0"
      },
      "source": [
        "#perform stemming and lower each word as well as remove duplicates\n",
        "\n",
        "words=[stemmer.stem(w.lower()) for w in words if w not in ignore]\n",
        "words=sorted(list(set(words)))\n",
        "\n",
        "#remove duplicate classes\n",
        "classes=sorted(list(set(classes)))\n",
        "\n",
        "print (len(documents), \"documents\")\n",
        "print (len(classes), \"classes\", classes)\n",
        "print (len(words), \"unique stemmed words\", words)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 documents\n",
            "21 classes ['age', 'bad_joke', 'doing_badly', 'doing_great', 'favorite_movie', 'favorite_show', 'good_joke', 'goodbye', 'greeting', 'hate', 'how_are_you', 'joke', 'like', 'name', 'netflix', 'quick_run', 'real_bot', 'sky_net_no', 'sky_net_yes', 'thanks', 'your_thoughts']\n",
            "107 unique stemmed words ['a', 'about', 'address', 'ag', 'al', 'am', 'any', 'anyon', 'ar', 'aw', 'awesom', 'bad', 'best', 'bet', 'bye', 'cal', 'can', 'chil', 'conscy', 'cool', 'cya', 'day', 'do', 'doe', 'doing', 'dumb', 'favorit', 'film', 'friend', 'funny', 'going', 'good', 'goodby', 'got', 'gre', 'hah', 'happy', 'hat', 'hav', 'hello', 'hey', 'hi', 'horr', 'how', 'hum', 'i', 'im', 'indee', 'is', 'it', 'jok', 'just', 'lat', 'leav', 'lik', 'lov', 'me', 'mean', 'movy', 'my', 'nah', 'nam', 'netflix', 'no', 'not', 'old', 'on', 'ow', 'real', 'robot', 'run', 'sad', 'scary', 'see', 'senty', 'should', 'show', 'singul', 'stupid', 'sup', 'tel', 'termin', 'terr', 'thank', 'thankyou', 'that', 'the', 'ther', 'think', 'thought', 'trash', 'tv', 'ty', 'up', 'very', 'wait', 'was', 'watch', 'wel', 'what', 'why', 'ye', 'yeah', 'yep', 'yo', 'you', 'yup']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1388GULyl5oS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aff835df-c09a-43eb-b5b5-037db1b96037"
      },
      "source": [
        "#create training data\n",
        "training=[]\n",
        "output=[]\n",
        "\n",
        "#create an empty array for output\n",
        "output_empty=[0]*len(classes)\n",
        "\n",
        "#create training set bag of words for each sentence\n",
        "for doc in documents:\n",
        "  #initialize bag of words\n",
        "  bag=[]\n",
        "  #list of tokenized words for the pattern\n",
        "  pattern_words=doc[0]\n",
        "  #stemming each word\n",
        "  pattern_words=[stemmer.stem(word.lower()) for word in pattern_words]\n",
        "  #create bag of words array\n",
        "  for w in words:\n",
        "    bag.append(1) if w in pattern_words else bag.append(0)\n",
        "    \n",
        "  #output is 1 for current tag and o for the rest of other tags\n",
        "  output_row=list(output_empty)\n",
        "  output_row[classes.index(doc[1])]=1\n",
        "    \n",
        "  training.append([bag,output_row])\n",
        "    \n",
        "#shuffling features and turning it into np.array\n",
        "random.shuffle(training)\n",
        "training=np.array(training)\n",
        "  \n",
        "#creating training lists\n",
        "train_x =list(training[:,0])\n",
        "train_y =list(training[:,1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-ebec8845702b>:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  training=np.array(training)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2TNEBYFpPBx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f31e8a80-181f-4e07-ad61-3441056eae62"
      },
      "source": [
        "#resetting underlying graph data\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "#building neural network\n",
        "net=tflearn.input_data(shape=[None, len(train_x[0])])\n",
        "net=tflearn.fully_connected(net,10)\n",
        "net=tflearn.fully_connected(net,10)\n",
        "net=tflearn.fully_connected(net,len(train_y[0]), activation='softmax')\n",
        "net=tflearn.regression(net)\n",
        "\n",
        "#defining model and setting up tensorboard\n",
        "model=tflearn.DNN(net, tensorboard_dir='tflearn_logs')\n",
        "\n",
        "#start training\n",
        "model.fit(train_x, train_y, n_epoch=1000, batch_size=8, show_metric=True)\n",
        "model.save('model.tflearn')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Step: 12999  | total loss: \u001b[1m\u001b[32m0.01518\u001b[0m\u001b[0m | time: 0.108s\n",
            "| Adam | epoch: 1000 | loss: 0.01518 - acc: 0.9975 -- iter: 96/99\n",
            "Training Step: 13000  | total loss: \u001b[1m\u001b[32m0.02453\u001b[0m\u001b[0m | time: 0.111s\n",
            "| Adam | epoch: 1000 | loss: 0.02453 - acc: 0.9978 -- iter: 99/99\n",
            "--\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LA_5QFbsUUc"
      },
      "source": [
        "import pickle\n",
        "pickle.dump({'word':words, 'classes':classes, 'train_x':train_x, 'train_y':train_y}, open(\"training_data\",\"wb\"))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl_Kv75avdJP"
      },
      "source": [
        "#restoring all the data structures\n",
        "data = pickle.load(open(\"training_data\",\"rb\"))\n",
        "\n",
        "words   =data['word']\n",
        "classes =data['classes']\n",
        "train_x =data['train_x']\n",
        "train_y =data['train_y']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue66f586wgQQ"
      },
      "source": [
        "with open('/content/intents.json') as json_data:\n",
        "    intents = json.load(json_data)\n",
        "  "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLVolYxww6rW"
      },
      "source": [
        "#load the saved model\n",
        "model.load('./model.tflearn')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeBXcDR5xBfM"
      },
      "source": [
        "def clean_up_sentence(sentence):\n",
        "  #tokenize the token\n",
        "  sentence_words=nltk.word_tokenize(sentence)\n",
        "  #stemming each word\n",
        "  sentence_words=[stemmer.stem(word.lower()) for word in sentence_words]\n",
        "  return sentence_words\n",
        "\n",
        "#return bag of word array:0 and 1 for each word in the bag that exists\n",
        "def bow(sentence, words, show_details=False):\n",
        "  #tokenize sentence\n",
        "  sentence_words=clean_up_sentence(sentence)\n",
        "  #generating bag of words\n",
        "  bag=[0] * len(words)\n",
        "  for s in sentence_words:\n",
        "    for i,w in enumerate(words):\n",
        "      if w ==s:\n",
        "        bag[i] = 1\n",
        "        \n",
        "        if show_details:\n",
        "          print(\"found in bag: %s\" % w)\n",
        "  return (np.array(bag))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDnZoojwyXI9"
      },
      "source": [
        "ERROR_THRESHOLD = 0.0\n",
        "def classify(sentence):\n",
        "  #generate probabilities from the model\n",
        "  results = model.predict([bow(sentence, words)])[0]\n",
        "  \n",
        "  #filter out prediction below a threshold\n",
        "  results = [[i,r] for i, r in enumerate(results) if r> ERROR_THRESHOLD]\n",
        "  \n",
        "  #sort by strength of probability\n",
        "  results.sort(key=lambda x: x[1], reverse=True)\n",
        "  return_list=[]\n",
        "  \n",
        "  for r in results:\n",
        "    return_list.append((classes[r[0]], r[1]))\n",
        "  \n",
        "  #return tuple of intent and probability\n",
        "  return return_list\n",
        "\n",
        "def response(sentence, userID='123', show_details=False):\n",
        "  results=classify(sentence)\n",
        "  \n",
        "  if results:\n",
        "    while results:\n",
        "      for i in intents['intents']:\n",
        "        if i['tag'] == results[0][0]:\n",
        "          return print(random.choice(i['responses']))\n",
        "      results.pop(0)\n",
        "  "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwmpKMu90gXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88979f86-f50b-49d5-996c-e8ddc7c147b6"
      },
      "source": [
        "classify('what are you hours of operation?')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('age', 0.73196995),\n",
              " ('name', 0.23676628),\n",
              " ('like', 0.018002672),\n",
              " ('hate', 0.01158891),\n",
              " ('how_are_you', 0.0016476118),\n",
              " ('your_thoughts', 1.2000149e-05),\n",
              " ('favorite_show', 9.512149e-06),\n",
              " ('netflix', 2.9025634e-06),\n",
              " ('favorite_movie', 1.5426389e-07),\n",
              " ('real_bot', 3.7290623e-10),\n",
              " ('thanks', 3.7637e-12),\n",
              " ('joke', 1.9875985e-12),\n",
              " ('goodbye', 1.4155486e-18),\n",
              " ('quick_run', 3.0335847e-22),\n",
              " ('greeting', 2.6086772e-22),\n",
              " ('good_joke', 1.25840196e-23),\n",
              " ('doing_great', 5.9756614e-26),\n",
              " ('sky_net_no', 1.5557308e-27),\n",
              " ('bad_joke', 3.155202e-28),\n",
              " ('doing_badly', 2.3315948e-32),\n",
              " ('sky_net_yes', 1.6078985e-33)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sY_y3G81NoI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ade5148-49ca-45fd-9db8-1c50247f51b0"
      },
      "source": [
        "response('Do you take credit cards?')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You owe me one\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6faVi3l1l9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6601dd3a-ab4c-4380-c8b4-6d579f619633"
      },
      "source": [
        "response('Bye')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I won't miss you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ByRPlyX2VrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bd3ac0a-9e91-440f-f459-38653de40638"
      },
      "source": [
        "response('good day')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mwahaha I will take over the world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_JBIxVB5-9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cbdec82-b0bd-4055-aba7-bf00eacbdcd6"
      },
      "source": [
        "response('Thank you')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You owe me one\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWoQZT8b6eSE"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}